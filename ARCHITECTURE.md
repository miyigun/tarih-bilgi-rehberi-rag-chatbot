# ğŸ—ï¸ Ã‡Ã¶zÃ¼m Mimarisi

Bu dokÃ¼manda Tarih Bilgi Rehberi Chatbot projesinin teknik mimarisi, kullanÄ±lan teknolojiler ve RAG pipeline detaylarÄ± aÃ§Ä±klanmaktadÄ±r.

## ğŸ“‹ Ä°Ã§indekiler
1. [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
2. [Teknoloji Stack](#teknoloji-stack)
3. [RAG Pipeline](#rag-pipeline)
4. [Sistem Mimarisi](#sistem-mimarisi)
5. [Veri AkÄ±ÅŸÄ±](#veri-akÄ±ÅŸÄ±)
6. [Performans ve Optimizasyon](#performans-ve-optimizasyon)

---

## ğŸ¯ Genel BakÄ±ÅŸ

### Problemin TanÄ±mÄ±
Tarih Ã¶ÄŸrencileri, araÅŸtÄ±rmacÄ±lar ve tarih meraklÄ±larÄ±nÄ±n gÃ¼venilir, kaynaklÄ± ve hÄ±zlÄ± TÃ¼rk Tarihi bilgisine eriÅŸim ihtiyacÄ± bulunmaktadÄ±r. Geleneksel bilgi arama yÃ¶ntemleri:
- DaÄŸÄ±nÄ±k kaynaklarda arama yapmak zaman alÄ±cÄ±
- Bilgi doÄŸruluÄŸunu teyit etmek zor
- Kaynak referanslarÄ±na ulaÅŸmak karmaÅŸÄ±k
- Kronolojik baÄŸlamÄ± anlamak zorlaÅŸabiliyor

### Ã‡Ã¶zÃ¼mÃ¼mÃ¼z
RAG (Retrieval Augmented Generation) tabanlÄ± bir chatbot ile:
- âœ… 7/24 kesintisiz eriÅŸim
- âœ… AnÄ±nda, kaynaklÄ± yanÄ±t verme
- âœ… Akademik kaynaklardan doÄŸrulanmÄ±ÅŸ bilgi
- âœ… DÃ¶nem ve kategori bazlÄ± filtreleme
- âœ… Kronolojik baÄŸlamÄ± koruma
- âœ… TDK ve TTK gibi gÃ¼venilir kaynaklara dayalÄ±

---

## ğŸ› ï¸ Teknoloji Stack

### 1. Backend Framework
**LangChain v0.1.0**
- RAG pipeline orkestrasyon
- JSON dokÃ¼man yÃ¼kleme ve iÅŸleme
- Tarihsel metadata yÃ¶netimi

### 2. Large Language Model (LLM)
**Google Gemini 2.0 Flash**
- **SeÃ§im Nedenleri:**
  - Ãœcretsiz API (gÃ¼nlÃ¼k 1500 request)
  - HÄ±zlÄ± yanÄ±t sÃ¼resi (~1-2 saniye)
  - TÃ¼rkÃ§e dil desteÄŸi (TÃ¼rk Tarihi iÃ§in kritik)
  - 1M token context window
  - Akademik ton ve terminoloji desteÄŸi
  
- **Alternatifler:**
  - OpenAI GPT-4 (Ã¼cretli, daha gÃ¼Ã§lÃ¼)
  - Anthropic Claude (Ã¼cretli)
  - Open-source modeller (Llama, Mistral)

### 3. Embedding Model
**sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**
- **Ã–zellikler:**
  - Ã‡ok dilli destek (TÃ¼rkÃ§e dahil)
  - 384 boyutlu vektÃ¶rler
  - HÄ±zlÄ± inference (~50ms/dokÃ¼man)
  - Hafif model (420MB)
  - Tarihsel terminolojiyi iyi yakalama
  
- **Performans:**
  - Cosine similarity ile yÃ¼ksek doÄŸruluk
  - Anlamsal benzerlik yakalama
  - CPU'da verimli Ã§alÄ±ÅŸma

### 4. Vector Database
**FAISS (Facebook AI Similarity Search)**
- **SeÃ§im Nedenleri:**
  - YÃ¼ksek hÄ±zlÄ± similarity search
  - CPU optimizasyonu
  - DÃ¼ÅŸÃ¼k memory footprint
  - Kolay entegrasyon
  
- **Index Tipi:** IndexFlatIP (Inner Product)
- **Metrik:** IP (Inner Product / Cosine Similarity)
- **Alternatifler:**
  - Pinecone (cloud-based, scalable)
  - Chroma (developer-friendly)
  - Weaviate (GraphQL API)

### 5. Web Framework
**Streamlit v1.29.0**
- **AvantajlarÄ±:**
  - Python-only development
  - HÄ±zlÄ± prototipleme
  - YerleÅŸik UI komponenleri
  - Kolay deployment
  
- **Ã–zellikler:**
  - Session management
  - Caching (@st.cache_resource)
  - Responsive design
  - DÃ¶nem bazlÄ± filtreleme desteÄŸi

---

## ğŸ”„ RAG Pipeline

### Pipeline Genel YapÄ±sÄ±

```
[JSON Veriler] â†’ [Parse & Metadata] â†’ [Chunking] â†’ [Embedding] â†’ [Vector DB]
                                                                        â†“
[KullanÄ±cÄ± Sorusu] â†’ [Query Embedding] â†’ [Similarity Search] â† [FAISS]
                                                â†“
                                          [Top-K Chunks]
                                          (DÃ¶nem, YÄ±l, Kategori ile zenginleÅŸtirilmiÅŸ)
                                                â†“
                                    [Context + Query] â†’ [LLM] â†’ [YanÄ±t]
```

### 1. Veri HazÄ±rlama (Data Preparation)

#### A. JSON Veri YÃ¼kleme
```python
Veri YapÄ±sÄ±:
{
  "id": "osmanli_001",
  "donem": "OsmanlÄ± Devleti",
  "alt_donem": "YÃ¼kselme DÃ¶nemi",
  "kategori": {
    "ana": "Siyasi Olaylar",
    "alt": "Fetihler"
  },
  "konu": "Ä°stanbul'un Fethi",
  "icerik": "Ä°stanbul, 29 MayÄ±s 1453 tarihinde...",
  "yil": 1453,
  "anahtar_kelimeler": ["Ä°stanbul", "Fatih Sultan Mehmed"],
  "etiketler": ["fetih", "askeri strateji"],
  "kaynak": "TÃ¼rk Tarih Kurumu",
  "kaynak_turu": "Kitap",
  "referans_link": "https://www.ttk.gov.tr/..."
}
```

**DÃ¶nemler:**
- Ä°slamiyet Ã–ncesi TÃ¼rk Tarihi
- Ä°lk TÃ¼rk-Ä°slam Devletleri
- Anadolu Beylikleri DÃ¶nemi
- OsmanlÄ± Devleti
- MillÃ® MÃ¼cadele DÃ¶nemi
- Cumhuriyet DÃ¶nemi

#### B. Preprocessing
```python
AdÄ±mlar:
1. JSON parse ve validasyon
2. Metadata zenginleÅŸtirme (dÃ¶nem, yÄ±l, kategori)
3. Ä°Ã§erik birleÅŸtirme (konu + icerik + anahtar kelimeler)
4. Ã–zel karakter temizleme (TÃ¼rkÃ§e karakterler korunur)
5. Fazla boÅŸluk kaldÄ±rma
```

#### C. Text Chunking
```python
RecursiveCharacterTextSplitter:
- chunk_size: 512 karakter
- chunk_overlap: 50 karakter
- separators: ["\n\n", "\n", ".", "!", "?", ",", " "]

Neden bu parametreler?
- 512: Tarihsel olaylarÄ± bÃ¼tÃ¼n tutmak iÃ§in optimal
- 50: Kronolojik baÄŸlamÄ± korumak iÃ§in overlap
- Separators: Olay akÄ±ÅŸÄ±nÄ±n bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ korur
```

**Chunk Stratejisi:**
```
Tarihsel Olay: "Ä°stanbul'un Fethi (1453)..."
â†“
Chunk 1: [Konu + Ä°lk Paragraf + Metadata]
Chunk 2: [Devam + SonuÃ§lar + Metadata]
Her chunk dÃ¶nem, yÄ±l, kategori bilgisi taÅŸÄ±r
```

### 2. Embedding Generation

```python
Model: paraphrase-multilingual-MiniLM-L12-v2
Input: Tarihsel metin chunk (512 karakter)
Output: 384-dimensional vector

Process:
1. Tokenization (TÃ¼rkÃ§e)
2. BERT encoding
3. Mean pooling
4. Normalization
5. Vector output (float32[384])
```

**Embedding Ã–rneÄŸi:**
```python
Text: "Malazgirt SavaÅŸÄ±, 1071 yÄ±lÄ±nda BÃ¼yÃ¼k SelÃ§uklu SultanÄ± Alparslan..."
â†“
Vector: [0.34, -0.21, 0.67, ..., 0.15]  # 384 dimension
```

### 3. Vector Storage (FAISS)

```python
Index Type: IndexFlatIP
- Exact search (brute force)
- IP (Inner Product) metric (KosinÃ¼s BenzerliÄŸi iÃ§in)
- No quantization
- Memory: ~1.5KB per vector

Index Creation:
dimension = 384
index = faiss.IndexFlatIP(dimension)
# VektÃ¶rler L2 normalize edildi (data_processing.py'de)
index.add(embeddings)  # numpy array (n_chunks, 384)

Metadata Storage:
- DÃ¶nem bilgisi
- YÄ±l bilgisi
- Kategori (ana/alt)
- Kaynak referansÄ±
- Etiketler
```

### 4. Retrieval Phase

#### A. Query Embedding
```python
User Query â†’ Same Embedding Model â†’ Query Vector (384-dim)

Ã–rnek:
"OsmanlÄ± Devleti'nin yÃ¼kselme dÃ¶nemi" â†’ [0.23, -0.41, ...]
```
#### Algorithm: K-Nearest Neighbors (KNN)
Metric: IP (Inner Product / Cosine Similarity)

Search Process:
1. Compute score: score = dot(query_vec, doc_vec)
2. Sort by score (descending)
3. Return top-k results with metadata
4. The returned score *is* the Cosine Similarity (Ã§Ã¼nkÃ¼ vektÃ¶rler L2 normalize edildi)

Parameters:
- top_k: 5 (en alakalÄ± 5 chunk)
- threshold: 0.3 (minimum similarity score)

Retrieved Data:
- Content (chunk metni)
- DÃ¶nem (OsmanlÄ± Devleti)
- YÄ±l (1453)
- Kaynak (TTK)
- Similarity score (0.87)
```

### 5. Generation Phase

#### A. Context Preparation
```python
Retrieved Chunks (5) â†’ Format with Metadata â†’ Context Text

Format:
"""
Kaynak 1 (OsmanlÄ± Devleti, 1453 - TÃ¼rk Tarih Kurumu):
[chunk 1 content]

---

Kaynak 2 (OsmanlÄ± Devleti, 1520 - TDK):
[chunk 2 content]

...
"""
```

#### B. Prompt Engineering (Tarih AsistanÄ± iÃ§in Ã–zelleÅŸtirilmiÅŸ)
```python
Prompt Template:
"""
Sen TÃ¼rk Tarihi konusunda uzmanlaÅŸmÄ±ÅŸ bir yapay zeka asistanÄ±sÄ±n.

BÄ°LGÄ° BANKASI:
{context}
(DÃ¶nem, yÄ±l ve kaynak bilgileri ile zenginleÅŸtirilmiÅŸ)

KULLANICI SORUSU:
{query}

YANIT KURALLARI:
1. Sadece bilgi bankasÄ±ndaki bilgileri kullan
2. Akademik ama anlaÅŸÄ±lÄ±r dil
3. Tarihsel olaylarÄ± kronolojik sÄ±rada anlat
4. Tarihleri, isimleri, yerleri net belirt
5. Kaynak referanslarÄ±nÄ± belirt (TTK, TDK)
6. Kronolojik baÄŸlamÄ± koru
7. Emoji kullanma, ciddi ve akademik ol

YANIT:
"""
```

#### C. LLM Generation
```python
Model: Gemini 1.5 Flash
Temperature: 0.7 (tarihsel doÄŸruluk iÃ§in dengeli)
Max tokens: 1024
Top-p: 0.9

Process:
1. Prompt â†’ Gemini API
2. Token generation (TÃ¼rkÃ§e akademik dil)
3. Response formatting
4. Kaynak referanslarÄ±nÄ± dahil etme
```

---

## ğŸ›ï¸ Sistem Mimarisi

### ModÃ¼ler YapÄ±

```
tarih-bilgi-rehberi-chatbot/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # JSON veri dosyalarÄ±
â”‚   â”‚   â”œâ”€â”€ islamiyet_oncesi.json
â”‚   â”‚   â”œâ”€â”€ ilk_turk_islam_devletleri.json
â”‚   â”‚   â”œâ”€â”€ anadolu_beylikleri.json
â”‚   â”‚   â”œâ”€â”€ osmanli_devleti.json
â”‚   â”‚   â”œâ”€â”€ milli_mucadele.json
â”‚   â”‚   â””â”€â”€ cumhuriyet.json
â”‚   â””â”€â”€ processed/                     # Ä°ÅŸlenmiÅŸ veri (opsiyonel)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ embeddings/                    # Embedding model cache
â”‚   â””â”€â”€ faiss_index/                   # FAISS index dosyalarÄ±
â”‚       â”œâ”€â”€ index.faiss                # Vector index
â”‚       â””â”€â”€ metadata.json              # Tarihsel metadata
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                    # Package init
â”‚   â”œâ”€â”€ data_processing.py             # JSON veri iÅŸleme
â”‚   â”œâ”€â”€ retrieval.py                   # FAISS retrieval
â”‚   â”œâ”€â”€ rag_system.py                  # RAG engine
â”‚   â””â”€â”€ utils.py                       # YardÄ±mcÄ± fonksiyonlar
â”‚
â”œâ”€â”€ app.py                             # Streamlit UI (Tarih temalÄ±)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                               # API keys
â”œâ”€â”€ setup.py                           # Kurulum scripti
â””â”€â”€ README.md                          # Proje dokÃ¼mantasyonu
```

### Veri AkÄ±ÅŸ DiyagramÄ±

```mermaid
graph TB
    A[KullanÄ±cÄ±] -->|Tarih Sorusu| B[Streamlit UI]
    B --> C[RAG System]
    C -->|Embed Query| D[Embedding Model]
    D --> E[FAISS Search]
    E -->|Top-K Chunks + Metadata| F[Context Builder]
    F -->|Context + Query| G[Gemini API]
    G -->|Akademik YanÄ±t| B
    B -->|YanÄ±t + Kaynaklar + DÃ¶nem| A
```

### Component Ä°liÅŸkileri

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Streamlit Frontend (Tarih TemalÄ±)     â”‚
â”‚  (Session, DÃ¶nem Filtreleri, Timeline)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RAG System Core (Tarih)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Retriever â”‚â—„â”€â”€â”€â”€â–ºâ”‚  Generator   â”‚      â”‚
â”‚  â”‚  +Metadata â”‚      â”‚  +Tarih AI   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚              â”‚
    â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS  â”‚  â”‚ Sentence â”‚  â”‚  Gemini   â”‚
â”‚ +Meta  â”‚  â”‚Transform â”‚  â”‚  (TÃ¼rkÃ§e) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Performans ve Optimizasyon

### 1. Caching Stratejileri

#### Streamlit Cache
```python
@st.cache_resource
def load_rag_system():
    # RAG sistem bir kez yÃ¼klenir
    # TÃ¼m kullanÄ±cÄ±lar aynÄ± instance'Ä± kullanÄ±r
    return RAGSystem()
```

#### Model Cache
```python
# Sentence Transformers otomatik cache
~/.cache/torch/sentence_transformers/
```

### 2. Performans Metrikleri

| Ä°ÅŸlem | SÃ¼re | Optimizasyon |
|-------|------|--------------|
| Model yÃ¼kleme | ~3s | Cache ile 0s |
| JSON parse | ~50ms/file | Batch processing |
| DokÃ¼man embedding | ~50ms/doc | Paralel iÅŸleme |
| Query embedding | ~30ms | - |
| FAISS search | ~5ms | Index optimizasyonu |
| LLM generation | ~2s | Streaming |
| **Toplam yanÄ±t** | **~2-3s** | - |

### 3. Scalability

#### Horizontal Scaling
```
Mevcut: Single instance
â†“
Ã–nerilen: Multi-instance + Load Balancer
- Nginx / HAProxy
- Multiple Streamlit instances
- Shared FAISS index (Read-only)
- DÃ¶nem bazlÄ± sharding (opsiyonel)
```

#### Vertical Scaling
```
RAM: 4GB â†’ 8GB (daha fazla dÃ¶nem verisi)
CPU: 2 core â†’ 4 core (daha hÄ±zlÄ± embedding)
```

### 4. Optimizasyon Ã–nerileri

#### A. Embedding Optimization
- **GPU kullanÄ±mÄ±**: CUDA desteÄŸi ile 10x hÄ±zlanma
- **Quantization**: Model boyutunu %75 azalt
- **Batch processing**: Birden fazla query paralel iÅŸle

#### B. FAISS Optimization
- **IVF Index**: 10K+ dokÃ¼man iÃ§in inverted file
- **DÃ¶nem bazlÄ± indexler**: Her dÃ¶nem iÃ§in ayrÄ± index
- **PQ (Product Quantization)**: Memory kullanÄ±mÄ±nÄ± azalt

#### C. LLM Optimization
- **Response streaming**: KullanÄ±cÄ± deneyimi iyileÅŸtir
- **Prompt caching**: Tekrarlayan tarih promptlarÄ± cache'le
- **Batch requests**: Birden fazla query tek API call

---

## ğŸ”’ GÃ¼venlik

### 1. API Key YÃ¶netimi
```python
# Environment variables
GOOGLE_API_KEY in .env
Never commit .env to Git
Use secrets management in production
```

### 2. Rate Limiting
```python
# Gemini API limits
1500 requests/day (free tier)
15 requests/minute

# Application level
Max 10 queries/minute per user (Ã¶nerilir)
```

### 3. Input Validation
```python
# Query validation
Max length: 500 characters
Sanitize special characters
Prevent prompt injection
Tarihsel iÃ§erik kontrolÃ¼
```

---

## ğŸ“Š Monitoring ve Logging

### Metrikler
- Response time
- Query success rate
- DÃ¶nem bazlÄ± kullanÄ±m
- Error rate
- Kaynak referans doÄŸruluÄŸu
- API usage

### Logging
```python
# Log levels
INFO: Normal operations (query, retrieval)
WARNING: Performance issues
ERROR: System failures
DEBUG: DÃ¶nem/kategori filtreleme
```

---

## ğŸš€ Gelecek Ä°yileÅŸtirmeler

1. **Multimodal Support**: GÃ¶rsel ve PDF dokÃ¼man analizi
2. **Conversation Memory**: Ã‡oklu soru-cevap baÄŸlamÄ±
3. **Hybrid Search**: Keyword + Semantic search
4. **Fine-tuning**: Domain-specific model
5. **A/B Testing**: Prompt optimization
6. **Analytics Dashboard**: KullanÄ±m istatistikleri

---

**Son GÃ¼ncelleme**: Ekim 2025  
**Versiyon**: 1.0.0